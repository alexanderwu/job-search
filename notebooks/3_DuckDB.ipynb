{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25dc0015",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import aw\n",
    "from aw import reload\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "import job_search.ai as ai\n",
    "from job_search.config import DS_HEALTH, DS_NORCAL, P_CACHE, VIEW_JOB_HTTPS\n",
    "import job_search.config as conf\n",
    "import job_search.dataset as ds\n",
    "import job_search.jobs as jobs\n",
    "import job_search.utils as utils\n",
    "from job_search.jobs import COLS, hmask, mask, tmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "96131c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>onsite</th>\n",
       "      <th>full_time</th>\n",
       "      <th>company</th>\n",
       "      <th>company_stock</th>\n",
       "      <th>company_summary</th>\n",
       "      <th>yoe</th>\n",
       "      <th>...</th>\n",
       "      <th>hash</th>\n",
       "      <th>chash</th>\n",
       "      <th>_len</th>\n",
       "      <th>hours</th>\n",
       "      <th>position</th>\n",
       "      <th>_position</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>median</th>\n",
       "      <th>bay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [days, title, location, salary, onsite, full_time, company, company_stock, company_summary, yoe, mgmt, job_summary, skills, hash, chash, _len, hours, position, _position, lower, upper, median, bay]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 23 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from job_search.config import P_DATA\n",
    "P_save_ = P_DATA / 'processed/2026-02-15/DS_NorCal' / 'DS_NorCal.html'\n",
    "# P_save = P_DATA / 'processed/2026-02-18/DS_NorCal' / 'DS_NorCal.html'\n",
    "# P_save = P_DATA / 'processed/2026-02-19/DS_NorCal' / 'DS_NorCal.html'\n",
    "# P_save = P_DATA / 'processed/2026-02-20/DS_NorCal' / 'DS_NorCal.html'\n",
    "P_save = P_DATA / 'processed/2026-02-21/DS_NorCal' / 'DS_NorCal.html'\n",
    "jdf = ds.load_jdf(P_save)\n",
    "jdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "405c8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash2position = dict(zip(jdf['hash'], jdf['position']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths = utils.paths(conf.P_URLS, mtime=\"2026-02-20\")\n",
    "paths = utils.paths(conf.P_DICT, mtime=\"2026-02-20\")\n",
    "# paths = utils.paths(conf.P_JOBS, mtime=\"2026-02-20\")\n",
    "\n",
    "stems = paths.apply(lambda x: x.stem)\n",
    "# hashes = stems.str.rsplit('.').str[-1]\n",
    "hashes = stems.str.rsplit('.').str[-2]\n",
    "positions = hashes.map(hash2position)\n",
    "\n",
    "# dst_series = (f\"{conf.P_URLS}\\\\\" + positions + '.' + hashes + '.html').dropna().apply(Path)\n",
    "# src_series = utils.paths(conf.P_URLS, mtime=\"2026-02-20\")[dst_series.index]\n",
    "\n",
    "dst_series = (f\"{conf.P_DICT}\\\\\" + positions + '.' + hashes + '.html.pkl').dropna().apply(Path)\n",
    "src_series = utils.paths(conf.P_DICT, mtime=\"2026-02-20\")[dst_series.index]\n",
    "\n",
    "# dst_series = (f\"{conf.P_JOBS}\\\\\" + positions + '.' + hashes + '.md').dropna().apply(Path)\n",
    "# src_series = utils.paths(conf.P_JOBS, mtime=\"2026-02-20\")[dst_series.index]\n",
    "\n",
    "for P_src, P_dst in zip(src_series, dst_series):\n",
    "    if not P_dst.exists():\n",
    "        print(P_src.name)\n",
    "        P_src.rename(P_dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0068a04",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd079b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = jobs.load_jobs()\n",
    "health_df = jobs.load_jobs().query('health')\n",
    "norcal_df = jobs.load_jobs().query('norcal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdf65642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_19431_row0_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_19431_row1_col0, #T_19431_row2_col1, #T_19431_row3_col0, #T_19431_row3_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_19431_row1_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 81.3%, transparent 81.3%);\n",
       "}\n",
       "#T_19431_row2_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 21.4%, transparent 21.4%);\n",
       "}\n",
       "#T_19431_row3_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 2.7%, transparent 2.7%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_19431\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_19431_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_19431_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_19431_level0_col2\" class=\"col_heading level0 col2\" >Size</th>\n",
       "      <th id=\"T_19431_level0_col3\" class=\"col_heading level0 col3\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_19431_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_19431_row0_col0\" class=\"data row0 col0\" >-</td>\n",
       "      <td id=\"T_19431_row0_col1\" class=\"data row0 col1\" >-</td>\n",
       "      <td id=\"T_19431_row0_col2\" class=\"data row0 col2\" >1984</td>\n",
       "      <td id=\"T_19431_row0_col3\" class=\"data row0 col3\" >100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19431_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_19431_row1_col0\" class=\"data row1 col0\" >Yes</td>\n",
       "      <td id=\"T_19431_row1_col1\" class=\"data row1 col1\" >-</td>\n",
       "      <td id=\"T_19431_row1_col2\" class=\"data row1 col2\" >1613</td>\n",
       "      <td id=\"T_19431_row1_col3\" class=\"data row1 col3\" >81.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19431_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_19431_row2_col0\" class=\"data row2 col0\" >-</td>\n",
       "      <td id=\"T_19431_row2_col1\" class=\"data row2 col1\" >Yes</td>\n",
       "      <td id=\"T_19431_row2_col2\" class=\"data row2 col2\" >425</td>\n",
       "      <td id=\"T_19431_row2_col3\" class=\"data row2 col3\" >21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_19431_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_19431_row3_col0\" class=\"data row3 col0\" >Yes</td>\n",
       "      <td id=\"T_19431_row3_col1\" class=\"data row3 col1\" >Yes</td>\n",
       "      <td id=\"T_19431_row3_col2\" class=\"data row3 col2\" >54</td>\n",
       "      <td id=\"T_19431_row3_col3\" class=\"data row3 col3\" >2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20d2ed2bef0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw.combo_sizes([set(norcal_df['_hash']), set(health_df['_hash'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b810c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee518_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 76.5%, transparent 76.5%);\n",
       "}\n",
       "#T_ee518_row1_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 38.4%, transparent 38.4%);\n",
       "}\n",
       "#T_ee518_row2_col2, #T_ee518_row3_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 22.1%, transparent 22.1%);\n",
       "}\n",
       "#T_ee518_row4_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 17.4%, transparent 17.4%);\n",
       "}\n",
       "#T_ee518_row5_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 16.0%, transparent 16.0%);\n",
       "}\n",
       "#T_ee518_row6_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 14.1%, transparent 14.1%);\n",
       "}\n",
       "#T_ee518_row7_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 11.9%, transparent 11.9%);\n",
       "}\n",
       "#T_ee518_row8_col2, #T_ee518_row9_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 11.6%, transparent 11.6%);\n",
       "}\n",
       "#T_ee518_row10_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee518\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee518_level0_col0\" class=\"col_heading level0 col0\" >technical_tools</th>\n",
       "      <th id=\"T_ee518_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_ee518_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_ee518_row0_col0\" class=\"data row0 col0\" >Python</td>\n",
       "      <td id=\"T_ee518_row0_col1\" class=\"data row0 col1\" >277</td>\n",
       "      <td id=\"T_ee518_row0_col2\" class=\"data row0 col2\" >76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_ee518_row1_col0\" class=\"data row1 col0\" >SQL</td>\n",
       "      <td id=\"T_ee518_row1_col1\" class=\"data row1 col1\" >139</td>\n",
       "      <td id=\"T_ee518_row1_col2\" class=\"data row1 col2\" >38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_ee518_row2_col0\" class=\"data row2 col0\" >PyTorch</td>\n",
       "      <td id=\"T_ee518_row2_col1\" class=\"data row2 col1\" >80</td>\n",
       "      <td id=\"T_ee518_row2_col2\" class=\"data row2 col2\" >22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_ee518_row3_col0\" class=\"data row3 col0\" >AWS</td>\n",
       "      <td id=\"T_ee518_row3_col1\" class=\"data row3 col1\" >80</td>\n",
       "      <td id=\"T_ee518_row3_col2\" class=\"data row3 col2\" >22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_ee518_row4_col0\" class=\"data row4 col0\" >TensorFlow</td>\n",
       "      <td id=\"T_ee518_row4_col1\" class=\"data row4 col1\" >63</td>\n",
       "      <td id=\"T_ee518_row4_col2\" class=\"data row4 col2\" >17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_ee518_row5_col0\" class=\"data row5 col0\" >R</td>\n",
       "      <td id=\"T_ee518_row5_col1\" class=\"data row5 col1\" >58</td>\n",
       "      <td id=\"T_ee518_row5_col2\" class=\"data row5 col2\" >16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_ee518_row6_col0\" class=\"data row6 col0\" >Kubernetes</td>\n",
       "      <td id=\"T_ee518_row6_col1\" class=\"data row6 col1\" >51</td>\n",
       "      <td id=\"T_ee518_row6_col2\" class=\"data row6 col2\" >14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_ee518_row7_col0\" class=\"data row7 col0\" >Tableau</td>\n",
       "      <td id=\"T_ee518_row7_col1\" class=\"data row7 col1\" >43</td>\n",
       "      <td id=\"T_ee518_row7_col2\" class=\"data row7 col2\" >11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_ee518_row8_col0\" class=\"data row8 col0\" >Spark</td>\n",
       "      <td id=\"T_ee518_row8_col1\" class=\"data row8 col1\" >42</td>\n",
       "      <td id=\"T_ee518_row8_col2\" class=\"data row8 col2\" >11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_ee518_row9_col0\" class=\"data row9 col0\" >Docker</td>\n",
       "      <td id=\"T_ee518_row9_col1\" class=\"data row9 col1\" >42</td>\n",
       "      <td id=\"T_ee518_row9_col2\" class=\"data row9 col2\" >11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee518_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_ee518_row10_col0\" class=\"data row10 col0\" >(Other)</td>\n",
       "      <td id=\"T_ee518_row10_col1\" class=\"data row10 col1\" >2095</td>\n",
       "      <td id=\"T_ee518_row10_col2\" class=\"data row10 col2\" >578.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20d234930b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_feb = jobs.load_jobs_feb()\n",
    "jobs_feb['technical_tools'].explode().pipe(aw.vcounts, 10, vmax=jobs_feb.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e5ca3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Top 7 Required (Domain Area, Expertise, Soft Skills):**  \n",
      "- Advanced degree in data science, bioinformatics, biostatistics, epidemiology, immunology, or public health with relevant experience  \n",
      "- Proficiency in Python, R, SAS, and SQL with strong statistical analysis skills  \n",
      "- Expertise in design and analysis of pharmacoepidemiological studies  \n",
      "- Experience in real-world evidence (RWD) study methodologies and data analysis  \n",
      "- Strong problem-solving and judgment in methodological selection for complex clinical studies  \n",
      "- Ability to collaborate effectively with interdisciplinary teams (scientists, engineers, product developers)  \n",
      "- Rigorous attention to detail and commitment to high-quality, timely analytics deliverables  \n",
      "\n",
      "**Top 7 Nice-to-Haves:**  \n",
      "- Experience with version control and software testing  \n",
      "- Familiarity with time-to-event analysis and survival modeling  \n",
      "- Background in oncology Phase II–IV trials or RWD studies (claims, EHR, registries)  \n",
      "- Hands-on experience supporting FDA regulatory submissions  \n",
      "- Experience in model building, validation, and data science team support  \n",
      "- Client-facing experience and comfort presenting findings to stakeholders  \n",
      "- Knowledge of machine learning applications in medical research (predictive/prognostic algorithms)\n"
     ]
    }
   ],
   "source": [
    "with open('jd.md') as f:\n",
    "    jd_md = f.read()\n",
    "print(ai.llm_extract(jd_md, verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3bb7d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_89d0a_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 0.3%, transparent 0.3%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_89d0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_89d0a_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_89d0a_level0_col1\" class=\"col_heading level0 col1\" >Total</th>\n",
       "      <th id=\"T_89d0a_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_89d0a_row0_col0\" class=\"data row0 col0\" >6</td>\n",
       "      <td id=\"T_89d0a_row0_col1\" class=\"data row0 col1\" >1984</td>\n",
       "      <td id=\"T_89d0a_row0_col2\" class=\"data row0 col2\" >0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20d2a895a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 6: https://hiring.cafe/viewjob/ev4uv7f3i917368a\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Top 7 Job Requirements (Domain Area, Expertise, Soft Skills)**  \n",
       "- **Healthcare domain expertise**: Deep understanding of clinical data, EHRs, claims data, and real-world data (RWD) sources.  \n",
       "- **Machine learning & AI proficiency**: Advanced experience with supervised/unsupervised ML, LLMs, and NLP applied to sparse, clinical datasets.  \n",
       "- **Data curation & integration**: Skills in multi-source data reconciliation, feature engineering, and data quality assessment.  \n",
       "- **Clinical data handling**: Expertise in unstructured clinical data abstraction and interpretation of structured/unstructured data.  \n",
       "- **Software engineering**: Experience building and deploying production-grade data tools and models.  \n",
       "- **Cross-functional collaboration**: Ability to work effectively with diverse teams, including clinical subject matter experts.  \n",
       "- **Problem-solving agility**: Creative, methodical approach to solving complex, ambiguous real-world data challenges.\n",
       "\n",
       "**Top 7 Nice-to-Haves**  \n",
       "- Familiarity with medical terminologies and ontologies (e.g., SNOMED, ICD).  \n",
       "- Experience with clinical subject matter experts in research or care settings.  \n",
       "- Background in software development or production system design.  \n",
       "- Strong analytical and critical thinking skills for evidence-based decision-making.  \n",
       "- Tolerance for ambiguity and iterative learning in dynamic environments.  \n",
       "- Proven ability to translate complex data insights into actionable outcomes.  \n",
       "- Experience with longitudinal dataset design and real-world evidence generation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d43d7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d43d7_level0_col0\" class=\"col_heading level0 col0\" >1328</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row0\" class=\"row_heading level0 row0\" >company_name</th>\n",
       "      <td id=\"T_d43d7_row0_col0\" class=\"data row0 col0\" >Verily Life Sciences</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row1\" class=\"row_heading level0 row1\" >title</th>\n",
       "      <td id=\"T_d43d7_row1_col0\" class=\"data row1 col0\" >Senior Data Scientist,  RWD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row2\" class=\"row_heading level0 row2\" >estimated_publish_date</th>\n",
       "      <td id=\"T_d43d7_row2_col0\" class=\"data row2 col0\" >2025-12-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row3\" class=\"row_heading level0 row3\" >requirements_summary</th>\n",
       "      <td id=\"T_d43d7_row3_col0\" class=\"data row3 col0\" >Advanced degree in quantitative field; 3+ years ML/AI with clinical data; experience with real-world data (EHR); strong Python.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row4\" class=\"row_heading level0 row4\" >job_category</th>\n",
       "      <td id=\"T_d43d7_row4_col0\" class=\"data row4 col0\" >Data and Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row5\" class=\"row_heading level0 row5\" >workplace_type</th>\n",
       "      <td id=\"T_d43d7_row5_col0\" class=\"data row5 col0\" >Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row6\" class=\"row_heading level0 row6\" >formatted_workplace_location</th>\n",
       "      <td id=\"T_d43d7_row6_col0\" class=\"data row6 col0\" >Mountain View or San Bruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row7\" class=\"row_heading level0 row7\" >technical_tools</th>\n",
       "      <td id=\"T_d43d7_row7_col0\" class=\"data row7 col0\" >['Python' 'NLP' 'LLMs' 'Machine Learning']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row8\" class=\"row_heading level0 row8\" >role_activities</th>\n",
       "      <td id=\"T_d43d7_row8_col0\" class=\"data row8 col0\" >['design datasets' 'build models' 'augment tools']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row9\" class=\"row_heading level0 row9\" >job_category</th>\n",
       "      <td id=\"T_d43d7_row9_col0\" class=\"data row9 col0\" >Data and Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row10\" class=\"row_heading level0 row10\" >seniority_level</th>\n",
       "      <td id=\"T_d43d7_row10_col0\" class=\"data row10 col0\" >Senior Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row11\" class=\"row_heading level0 row11\" >workplace_type</th>\n",
       "      <td id=\"T_d43d7_row11_col0\" class=\"data row11 col0\" >Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row12\" class=\"row_heading level0 row12\" >formatted_workplace_location</th>\n",
       "      <td id=\"T_d43d7_row12_col0\" class=\"data row12 col0\" >Mountain View or San Bruno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row13\" class=\"row_heading level0 row13\" >company_tagline</th>\n",
       "      <td id=\"T_d43d7_row13_col0\" class=\"data row13 col0\" >Verily Life Sciences LLC is a research organization. The Company is focused on the study of life sciences, health care, and biotechnology.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row14\" class=\"row_heading level0 row14\" >_hash</th>\n",
       "      <td id=\"T_d43d7_row14_col0\" class=\"data row14 col0\" >ev4uv7f3i917368a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row15\" class=\"row_heading level0 row15\" >health</th>\n",
       "      <td id=\"T_d43d7_row15_col0\" class=\"data row15 col0\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d43d7_level0_row16\" class=\"row_heading level0 row16\" >norcal</th>\n",
       "      <td id=\"T_d43d7_row16_col0\" class=\"data row16 col0\" >True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20d2a8880e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size:16px;max-width:45rem;margin:0 auto;\">**Who We Are**\n",
       "==============\n",
       "\n",
       "Verily is a subsidiary of Alphabet that is using a data-driven approach to change the way people manage their health and the way healthcare is delivered. Launched from Google X in 2015, our purpose is to bring the promise of precision health to everyone, every day. We are focused on generating and activating data from a variety of sources, including clinical, social, behavioral and the real world, to arrive at the best solutions for a person based on a comprehensive view of the evidence. Our unique expertise and capabilities in technology, data science and healthcare enable the entire healthcare ecosystem to drive better health outcomes.\n",
       "\n",
       "**Description**\n",
       "===============\n",
       "\n",
       "As a Senior Data Scientist at Verily, you will be supporting our core mission to drive innovation in evidence generation for research and care decisions. We are building new types of longitudinal datasets that have foundations of RWD sources, such as EHRs (electronic health records) and claims data, and are augmented with prospective data collection. You will develop and deploy models that enable scalable curation of RWD. This will include multi-source integrations and reconciliations, creating derived features from the source data (e.g., abstraction of clinical concepts from unstructured data), and facilitating data quality assessments. You will work with a diverse cross-functional team to build reusable and scalable tools and to deliver products that unlock information from structured and unstructured clinical data.\n",
       "\n",
       "**Responsibilities**\n",
       "====================\n",
       "\n",
       "* Work closely with cross-functional partners to design and create longitudinal datasets integrating multiple data sources.\n",
       "* Build and implement highly accurate machine learning models / <span style=\"color: rebeccapurple\">AI</span> tools using sparsely labeled healthcare datasets.\n",
       "* Implement, build on and augment existing LLM/<span style=\"color: rebeccapurple\">NLP</span> tools to maximize the value of using unstructured medical data across a range of research and care applications.\n",
       "* Become an expert in our data’s capabilities and limitations. Solve difficult, non-routine analysis problems, handling data challenges from a real-world setting.\n",
       "\n",
       "**Qualifications**\n",
       "==================\n",
       "\n",
       "Minimum qualifications\n",
       "\n",
       "* Advanced degree in a quantitative discipline (e.g., data sciences, statistics, biomedical informatics, computer science, applied mathematics, or similar), or equivalent practical experience.\n",
       "* 3+ years experience applying advanced machine learning and <span style=\"color: rebeccapurple\">AI</span> techniques (supervised and unsupervised methods, <span style=\"color: rebeccapurple\">LLMs</span>, <span style=\"color: rebeccapurple\">NLP</span>) to clinical data.\n",
       "* Direct experience working with and curating real-world data, such as EHR, including a deep understanding of the complexities of this structured and unstructured clinical data.\n",
       "* Strong proficiency in <span style=\"color: rebeccapurple\">Python</span>.\n",
       "\n",
       "Preferred qualifications\n",
       "\n",
       "* Familiarity with medical terminologies and ontologies.\n",
       "* Familiarity with software engineering practices and experience developing production software.\n",
       "* Experience working with clinical subject matter experts.\n",
       "* Ability to work cross-functionally on teams, with a tolerance for ambiguity.\n",
       "* Creative and methodical problem solving: understand needs, identify options, form hypotheses, generate robust results, make informed decisions, and learn faster through feedback.\n",
       "\n",
       "This role is eligible for Verily-sponsored immigration support.\n",
       "\n",
       "The US base salary range for this full-time position is $119,000 - $169,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.\n",
       "\n",
       "*Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.*\n",
       "\n",
       "Verily Life Sciences LLC is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please [click here](https://verily.com/about-us/careers). If you'd like more information on your EEO rights under the law, please [click here](https://www.eeoc.gov/sites/default/files/2023-06/22-088_EEOC_KnowYourRights6.12ScreenRdr.pdf).\n",
       "\n",
       "If you have a need that requires accommodation, please let us know by completing our [Accommodations for Applicants form](https://docs.google.com/forms/d/e/1FAIpQLScOmgxJwtzHb_dhc9YD-dUUnprG3yiU5URWbU2xgShDrmhWYA/viewform).</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jobs.display_mask('rwd', 1, jobs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c54e14cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e8c0b_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 78.1%, transparent 78.1%);\n",
       "}\n",
       "#T_e8c0b_row1_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 39.5%, transparent 39.5%);\n",
       "}\n",
       "#T_e8c0b_row2_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 22.6%, transparent 22.6%);\n",
       "}\n",
       "#T_e8c0b_row3_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 22.3%, transparent 22.3%);\n",
       "}\n",
       "#T_e8c0b_row4_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 18.3%, transparent 18.3%);\n",
       "}\n",
       "#T_e8c0b_row5_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 16.0%, transparent 16.0%);\n",
       "}\n",
       "#T_e8c0b_row6_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 15.8%, transparent 15.8%);\n",
       "}\n",
       "#T_e8c0b_row7_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 13.0%, transparent 13.0%);\n",
       "}\n",
       "#T_e8c0b_row8_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 12.2%, transparent 12.2%);\n",
       "}\n",
       "#T_e8c0b_row9_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 10.9%, transparent 10.9%);\n",
       "}\n",
       "#T_e8c0b_row10_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 100.0%, transparent 100.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e8c0b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e8c0b_level0_col0\" class=\"col_heading level0 col0\" >technical_tools</th>\n",
       "      <th id=\"T_e8c0b_level0_col1\" class=\"col_heading level0 col1\" >N</th>\n",
       "      <th id=\"T_e8c0b_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_e8c0b_row0_col0\" class=\"data row0 col0\" >Python</td>\n",
       "      <td id=\"T_e8c0b_row0_col1\" class=\"data row0 col1\" >790</td>\n",
       "      <td id=\"T_e8c0b_row0_col2\" class=\"data row0 col2\" >78.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_e8c0b_row1_col0\" class=\"data row1 col0\" >SQL</td>\n",
       "      <td id=\"T_e8c0b_row1_col1\" class=\"data row1 col1\" >400</td>\n",
       "      <td id=\"T_e8c0b_row1_col2\" class=\"data row1 col2\" >39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_e8c0b_row2_col0\" class=\"data row2 col0\" >PyTorch</td>\n",
       "      <td id=\"T_e8c0b_row2_col1\" class=\"data row2 col1\" >229</td>\n",
       "      <td id=\"T_e8c0b_row2_col2\" class=\"data row2 col2\" >22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_e8c0b_row3_col0\" class=\"data row3 col0\" >AWS</td>\n",
       "      <td id=\"T_e8c0b_row3_col1\" class=\"data row3 col1\" >226</td>\n",
       "      <td id=\"T_e8c0b_row3_col2\" class=\"data row3 col2\" >22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "      <td id=\"T_e8c0b_row4_col0\" class=\"data row4 col0\" >TensorFlow</td>\n",
       "      <td id=\"T_e8c0b_row4_col1\" class=\"data row4 col1\" >185</td>\n",
       "      <td id=\"T_e8c0b_row4_col2\" class=\"data row4 col2\" >18.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "      <td id=\"T_e8c0b_row5_col0\" class=\"data row5 col0\" >Kubernetes</td>\n",
       "      <td id=\"T_e8c0b_row5_col1\" class=\"data row5 col1\" >162</td>\n",
       "      <td id=\"T_e8c0b_row5_col2\" class=\"data row5 col2\" >16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "      <td id=\"T_e8c0b_row6_col0\" class=\"data row6 col0\" >R</td>\n",
       "      <td id=\"T_e8c0b_row6_col1\" class=\"data row6 col1\" >160</td>\n",
       "      <td id=\"T_e8c0b_row6_col2\" class=\"data row6 col2\" >15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_e8c0b_row7_col0\" class=\"data row7 col0\" >Spark</td>\n",
       "      <td id=\"T_e8c0b_row7_col1\" class=\"data row7 col1\" >132</td>\n",
       "      <td id=\"T_e8c0b_row7_col2\" class=\"data row7 col2\" >13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_e8c0b_row8_col0\" class=\"data row8 col0\" >Docker</td>\n",
       "      <td id=\"T_e8c0b_row8_col1\" class=\"data row8 col1\" >123</td>\n",
       "      <td id=\"T_e8c0b_row8_col2\" class=\"data row8 col2\" >12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row9\" class=\"row_heading level0 row9\" >10</th>\n",
       "      <td id=\"T_e8c0b_row9_col0\" class=\"data row9 col0\" >Java</td>\n",
       "      <td id=\"T_e8c0b_row9_col1\" class=\"data row9 col1\" >110</td>\n",
       "      <td id=\"T_e8c0b_row9_col2\" class=\"data row9 col2\" >10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e8c0b_level0_row10\" class=\"row_heading level0 row10\" >11</th>\n",
       "      <td id=\"T_e8c0b_row10_col0\" class=\"data row10 col0\" >(Other)</td>\n",
       "      <td id=\"T_e8c0b_row10_col1\" class=\"data row10 col1\" >5582</td>\n",
       "      <td id=\"T_e8c0b_row10_col2\" class=\"data row10 col2\" >551.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eae64d2900>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs2026 = jobs.load_jobs2026()\n",
    "jobs2026['technical_tools'].explode().pipe(aw.vcounts, 10, vmax=jobs2026.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4eecae3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        ayuq0wq9ny3wqxtg\n",
       "1                                        22j8xtd38y7lplmj\n",
       "2                                        a8agvynj2p1vo28i\n",
       "3                                        n0x4f7gj6mzaj643\n",
       "4                                        epo57dibdxaeozbo\n",
       "                              ...                        \n",
       "6362                                     i9lgeyoj1ftweb02\n",
       "6363                                     n9zeq518k5hluu1j\n",
       "6364    bGV2ZXJfX19hcnRlcmEtMl9fXzhhM2I2NjE2LTY0ODItNG...\n",
       "6365                                     1ozhyr66wweestk2\n",
       "6366                                     e1ddsvxgd4u70ijo\n",
       "Name: hash, Length: 6367, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.load_jdf_dict()['ALL']['hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec5d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d8b35_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 0.9%, transparent 0.9%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d8b35\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d8b35_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_d8b35_level0_col1\" class=\"col_heading level0 col1\" >Total</th>\n",
       "      <th id=\"T_d8b35_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d8b35_row0_col0\" class=\"data row0 col0\" >6</td>\n",
       "      <td id=\"T_d8b35_row0_col1\" class=\"data row0 col1\" >679</td>\n",
       "      <td id=\"T_d8b35_row0_col2\" class=\"data row0 col2\" >0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff562cc170>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 6: https://hiring.cafe/viewjob/gj9jygwiv8sqyyu2\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Top 7 Job Requirements:**\n",
       "\n",
       "- **Domain Area:** Deep expertise in cloud infrastructure and enterprise software deployment  \n",
       "- **Expertise:** Proven experience in designing, managing, and optimizing scalable, secure cloud environments  \n",
       "- **Soft Skills:** Strong communication and collaboration skills to work across cross-functional teams  \n",
       "- **Problem-Solving:** Ability to diagnose complex technical issues and implement effective, long-term solutions  \n",
       "- **Project Management:** Experience leading technical projects from planning to delivery with clear timelines  \n",
       "- **Security Awareness:** Strong understanding of security best practices and compliance requirements  \n",
       "- **Adaptability:** Capacity to quickly learn new technologies and adapt to evolving business needs  \n",
       "\n",
       "**Top 7 Nice-to-Haves:**\n",
       "\n",
       "- Experience with containerization (e.g., Kubernetes) and microservices architecture  \n",
       "- Familiarity with DevOps toolchains and CI/CD pipelines  \n",
       "- Background in automation and infrastructure-as-code (IaC) practices  \n",
       "- Knowledge of multi-cloud environments or hybrid cloud strategies  \n",
       "- Experience with monitoring, logging, and observability tools  \n",
       "- Certification in cloud platforms (e.g., AWS, Azure, GCP)  \n",
       "- Experience working in agile or iterative development environments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9b56a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9b56a_level0_col0\" class=\"col_heading level0 col0\" >353</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row0\" class=\"row_heading level0 row0\" >company_name</th>\n",
       "      <td id=\"T_9b56a_row0_col0\" class=\"data row0 col0\" >Gem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row1\" class=\"row_heading level0 row1\" >title</th>\n",
       "      <td id=\"T_9b56a_row1_col0\" class=\"data row1 col0\" >Campfire.AI AI Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row2\" class=\"row_heading level0 row2\" >estimated_publish_date</th>\n",
       "      <td id=\"T_9b56a_row2_col0\" class=\"data row2 col0\" >2026-01-21 19:32:14.129000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row3\" class=\"row_heading level0 row3\" >requirements_summary</th>\n",
       "      <td id=\"T_9b56a_row3_col0\" class=\"data row3 col0\" >Full-time AI engineer role in San Francisco requiring ML expertise.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row4\" class=\"row_heading level0 row4\" >technical_tools</th>\n",
       "      <td id=\"T_9b56a_row4_col0\" class=\"data row4 col0\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9b56a_level0_row5\" class=\"row_heading level0 row5\" >_hash</th>\n",
       "      <td id=\"T_9b56a_row5_col0\" class=\"data row5 col0\" >gj9jygwiv8sqyyu2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff562ca1e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size:16px;max-width:45rem;margin:0 auto;\">  \n",
       "\n",
       "Compensation\n",
       "------------\n",
       "\n",
       "The base pay range for this role is $140,000 – $160,000 per year.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrase = 'we'\n",
    "job_ii = 1\n",
    "_mask = ~mask(phrase)\n",
    "################################################################################\n",
    "ii = job_ii - 1\n",
    "# dissplay(aw.perc(_mask))\n",
    "if any(_mask):\n",
    "    _mask_df = jobs2026[_mask]\n",
    "    _mask_hash = _mask_df['_hash'].iloc[ii]\n",
    "    print(f'{job_ii} of {_mask.sum()}: ' + VIEW_JOB_HTTPS + _mask_hash)\n",
    "\n",
    "    job_md = jobs.hash2md(_mask_hash)\n",
    "    ai.llm_extract(job_md, verbose=True)\n",
    "    display(_mask_df.query('_hash == @_mask_hash').drop(columns=['_md', 'description']).T.style)\n",
    "    jobs.display_hash(_mask_hash)\n",
    "    # print(job_md)\n",
    "else:\n",
    "    print(f'No match for: {phrase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ac24fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_532bc_row0_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 100.0%, transparent 100.0%);\n",
       "}\n",
       "#T_532bc_row1_col0, #T_532bc_row2_col1, #T_532bc_row3_col0, #T_532bc_row3_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_532bc_row1_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 85.0%, transparent 85.0%);\n",
       "}\n",
       "#T_532bc_row2_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 81.2%, transparent 81.2%);\n",
       "}\n",
       "#T_532bc_row3_col3 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 66.1%, transparent 66.1%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_532bc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_532bc_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_532bc_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_532bc_level0_col2\" class=\"col_heading level0 col2\" >Size</th>\n",
       "      <th id=\"T_532bc_level0_col3\" class=\"col_heading level0 col3\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_532bc_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_532bc_row0_col0\" class=\"data row0 col0\" >-</td>\n",
       "      <td id=\"T_532bc_row0_col1\" class=\"data row0 col1\" >-</td>\n",
       "      <td id=\"T_532bc_row0_col2\" class=\"data row0 col2\" >632</td>\n",
       "      <td id=\"T_532bc_row0_col3\" class=\"data row0 col3\" >100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_532bc_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_532bc_row1_col0\" class=\"data row1 col0\" >Yes</td>\n",
       "      <td id=\"T_532bc_row1_col1\" class=\"data row1 col1\" >-</td>\n",
       "      <td id=\"T_532bc_row1_col2\" class=\"data row1 col2\" >537</td>\n",
       "      <td id=\"T_532bc_row1_col3\" class=\"data row1 col3\" >85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_532bc_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "      <td id=\"T_532bc_row2_col0\" class=\"data row2 col0\" >-</td>\n",
       "      <td id=\"T_532bc_row2_col1\" class=\"data row2 col1\" >Yes</td>\n",
       "      <td id=\"T_532bc_row2_col2\" class=\"data row2 col2\" >513</td>\n",
       "      <td id=\"T_532bc_row2_col3\" class=\"data row2 col3\" >81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_532bc_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "      <td id=\"T_532bc_row3_col0\" class=\"data row3 col0\" >Yes</td>\n",
       "      <td id=\"T_532bc_row3_col1\" class=\"data row3 col1\" >Yes</td>\n",
       "      <td id=\"T_532bc_row3_col2\" class=\"data row3 col2\" >418</td>\n",
       "      <td id=\"T_532bc_row3_col3\" class=\"data row3 col3\" >66.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff46144680>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aw.combo_sizes([hmask('python'), hmask('job')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_mask = jobs2026['description'].str.lower().str.contains(r'\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71837983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa907_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 29.0%, transparent 29.0%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa907\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_aa907_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_aa907_level0_col1\" class=\"col_heading level0 col1\" >Total</th>\n",
       "      <th id=\"T_aa907_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_aa907_row0_col0\" class=\"data row0 col0\" >197</td>\n",
       "      <td id=\"T_aa907_row0_col1\" class=\"data row0 col1\" >679</td>\n",
       "      <td id=\"T_aa907_row0_col2\" class=\"data row0 col2\" >29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff46350f80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_mask.pipe(aw.perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df731a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size:16px;max-width:45rem;margin:0 auto;\">**Company Description:**\n",
       "\n",
       "**Our Mission**\n",
       "\n",
       "At Palo Alto Networks® everything starts and ends with our mission:\n",
       "\n",
       "Being the cybersecurity partner of choice, protecting our digital way of life.  \n",
       "Our vision is a world where each day is safer and more secure than the one before. We are a company built on the foundation of challenging and disrupting the way things are done, and we’re looking for innovators who are as committed to shaping the future of cybersecurity as we are.\n",
       "\n",
       "**Who We Are**\n",
       "\n",
       "We believe collaboration thrives in person. That’s why most of our teams work from the office full time, with flexibility when it’s needed. This model supports real-time problem-solving, stronger relationships, and the kind of precision that drives great outcomes.\n",
       "\n",
       "**Job Description:**\n",
       "\n",
       "**Your Career**\n",
       "\n",
       "Palo Alto Networks is committed to <span style=\"color: rebeccapurple\">AI</span> security in the emerging <span style=\"color: rebeccapurple\">AI</span> era. The <span style=\"color: rebeccapurple\">AI</span> security cloud service engineering team is the core engineering team to build a solid product to assure the runtime security of our customers when they are using <span style=\"color: rebeccapurple\">AI</span>, especially LLM services.\n",
       "\n",
       "**Your Impact**\n",
       "\n",
       "* Collaborate with product managers, cybersecurity researchers, <span style=\"color: rebeccapurple\">AI</span> application researchers and infrastructure software engineers\n",
       "* Design and build an innovative and solid products to ensure our customers can use <span style=\"color: rebeccapurple\">AI</span> service securely\n",
       "* Participate in all phases of the product development cycle, from definition, design, through implementation and test\n",
       "* Implement real-time security services to customers\n",
       "* Work with PLM on new feature requirement\n",
       "* Work with QA and DevOps on new release deployment\n",
       "\n",
       "**Qualifications:**\n",
       "\n",
       "**Your Experience**\n",
       "\n",
       "* Solid golang/python programming skills\n",
       "* Solid knowledge on HTTP 1.1/HTTP2 protocols and <span style=\"color: rebeccapurple\">gRPC</span>\n",
       "* Profound knowledge on web service proxy technology especially on envoy and web assembly\n",
       "* Experience in designing large distributed system and web services in the cloud\n",
       "* Deep knowledge in GCP platform is a plus\n",
       "* Familiar with major CSP LLM foundation models is a plus\n",
       "* The candidate should be a good problem solver\n",
       "* Master's degree in computer science or equivalent or equivalent military experience required\n",
       "\n",
       "**Additional Information:**\n",
       "\n",
       "**The Team**\n",
       "\n",
       "To stay ahead of the curve, it’s critical to know where the curve is, and how to anticipate the changes we may be facing. For the fastest growing cybersecurity company, the curve is the evolution of cyberattacks, and the products and services that proactively address them. As a predictive enterprise environment, we analyze petabytes of data that pass through our walls daily and we hire the most talented minds in data science to build creative predictive analytics and data science solutions for our cybersecurity solutions.\n",
       "\n",
       "We define the industry, instead of waiting for directions. We need individuals who feel comfortable in ambiguity, excited by the prospect of a challenge, and empowered by the unknown risks facing our everyday lives that are only enabled by a secure digital environment.\n",
       "\n",
       "**Compensation Disclosure**\n",
       "\n",
       "The compensation offered for this position will depend on qualifications, experience, and work location. For candidates who receive an offer at the posted level, the starting base salary (for non-sales roles) or base salary + commission target (for sales/commissioned roles) is expected to be between $126000/YR - $204500/YR. The offered compensation may also include restricted stock units and a bonus. A description of our employee benefits may be found [here](http://benefits.paloaltonetworks.com/).\n",
       "\n",
       "**Our Commitment**  \n",
       "  \n",
       "We’re problem solvers that take risks and challenge cybersecurity’s status quo. It’s simple: we can’t accomplish our mission without diverse teams innovating, together.\n",
       "\n",
       "We are committed to providing reasonable accommodations for all qualified individuals with a disability. If you require assistance or accommodation due to a disability or special need, please contact us at  [accommodations@paloaltonetworks.com](mailto:accommodations@paloaltonetworks.com).\n",
       "\n",
       "Palo Alto Networks is an equal opportunity employer. We celebrate diversity in our workplace, and all qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or other legally protected characteristics.\n",
       "\n",
       "All your information will be kept confidential according to EEO guidelines.\n",
       "\n",
       "Is role eligible for Immigration Sponsorship?: Yes</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# jobs2026[python_mask & ~Python_mask]\n",
    "jobs.display_hash('um7fm1qwwuj1s52p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "915c7dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fa5b3_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 77.8%, transparent 77.8%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fa5b3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_fa5b3_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_fa5b3_level0_col1\" class=\"col_heading level0 col1\" >Total</th>\n",
       "      <th id=\"T_fa5b3_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_fa5b3_row0_col0\" class=\"data row0 col0\" >528</td>\n",
       "      <td id=\"T_fa5b3_row0_col1\" class=\"data row0 col1\" >679</td>\n",
       "      <td id=\"T_fa5b3_row0_col2\" class=\"data row0 col2\" >77.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff46304f20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs2026['description'].str.contains('Python').pipe(aw.perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eabee091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0abd_row0_col2 {\n",
       "  width: 10em;\n",
       "  background: linear-gradient(90deg, #543b66 79.1%, transparent 79.1%);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0abd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c0abd_level0_col0\" class=\"col_heading level0 col0\" >N</th>\n",
       "      <th id=\"T_c0abd_level0_col1\" class=\"col_heading level0 col1\" >Total</th>\n",
       "      <th id=\"T_c0abd_level0_col2\" class=\"col_heading level0 col2\" >%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c0abd_row0_col0\" class=\"data row0 col0\" >537</td>\n",
       "      <td id=\"T_c0abd_row0_col1\" class=\"data row0 col1\" >679</td>\n",
       "      <td id=\"T_c0abd_row0_col2\" class=\"data row0 col2\" >79.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ff46353c50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(jobs2026['description'].str.lower().str.contains('python')).pipe(aw.perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998485a",
   "metadata": {},
   "source": [
    "## BM25s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2061522d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource module not available on Windows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83216a86cd040498592370095958888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3f3c87cdea4254806e5348d05355b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Count Tokens:   0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c733fd9a934942906e40ca84b8adfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Compute Scores:   0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bm25s\n",
    "from job_search.config import VIEW_JOB_HTTPS\n",
    "\n",
    "jobs2026 = jobs.load_jobs2026()\n",
    "corpus = jobs2026['_md']\n",
    "corpus_tokens = bm25s.tokenize(corpus)\n",
    "retriever = bm25s.BM25(corpus=corpus)\n",
    "retriever.index(corpus_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8af6e675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ff4e7cb8b446e480978703ed3b5dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f70e72684649ce9897686a01adcdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# weight_mask = (1 - 0.01*(pd.Timestamp.utcnow() - jobs2026['estimated_publish_date'].dt.tz_localize('UTC')).dt.days).clip(lower=0).values\n",
    "weight_mask = (1 - 0.01*(jobs2026['estimated_publish_date'].max() - jobs2026['estimated_publish_date']).dt.days).clip(lower=0).values\n",
    "\n",
    "def retrieve(query, k=15):\n",
    "    query_tokens = bm25s.tokenize(query)\n",
    "    _docs, _scores = retriever.retrieve(query_tokens, corpus=jobs2026['_hash'], weight_mask=weight_mask, backend_selection=\"auto\", k=15)\n",
    "    docs, scores = _docs.ravel(), _scores.ravel()\n",
    "    return docs, scores\n",
    "\n",
    "query = \"health\"\n",
    "docs, scores = retrieve(query)\n",
    "# pd.DataFrame({\n",
    "#     'docs': docs,\n",
    "#     'scores': scores,\n",
    "# }).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3133ac06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c480dd6a623b4a51b55a2f2fe8476804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split strings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faa390f3ac045498a78e8feb7e06673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BM25S Retrieve:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hiring.cafe/viewjob/xswtb7x6dfpuf3n4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size:16px;max-width:45rem;margin:0 auto;\">Our Mission and Vision\n",
       "======================\n",
       "\n",
       "Unlearn exists to transform clinical development by making every trial smarter. We harness data, <span style=\"color: rebeccapurple\">AI</span>, and digital twins to enable faster, more robust studies that bring life-saving treatments to patients faster. This mission drives everything we do as we partner with biopharmaceutical companies to redesign how clinical trials are planned, run, and analyzed.\n",
       "\n",
       "We are defining the future of clinical development with unmatched scientific credibility, replacing uncertainty with <span style=\"color: rebeccapurple\">AI</span>-powered precision so decisions are clearer and trials are stronger. We don’t just disrupt the pharmaceutical industry, we create lasting change.\n",
       "\n",
       "We believe <span style=\"color: rebeccapurple\">AI</span> will define the future of medicine, and we are committed to building that future responsibly, rigorously, and in close collaboration with our partners in clinical development.\n",
       "\n",
       "About Our Team\n",
       "==============\n",
       "\n",
       "We come from a variety of backgrounds ranging from machine learning to marketing—but regardless of where we come from, Unlearners share some common traits:\n",
       "\n",
       "* **Unlearners are ambitious**; we aren’t intimidated by big, challenging goals.\n",
       "* **Unlearners are disciplined experimenters**; we break down our big goals into smaller chunks and meet as often as necessary to track our velocity and iterate quickly.\n",
       "* **Unlearners are gritty**; we never give up, setbacks just make us try harder.\n",
       "* **Unlearners are receptive to new ideas**; in fact, we hate being stuck with the status quo\n",
       "* **Unlearners are storytellers**; sharing information with each other and with the world is super important, too important to be boring. And, last but not least,\n",
       "* **Unlearners are team-oriented**; we put the mission first, the company second, the team third, and individuals last.\n",
       "\n",
       "Headquartered in San Francisco, Unlearn was founded in 2017 by a team of world-class machine learning scientists. We have raised venture capital from top tier investors such as Altimeter, Insight Partners, Radical Ventures, 8VC, DCVC, and DCVC Bio, and completed our $50 million Series C in January 2024.\n",
       "\n",
       "**If our purpose and culture resonate with you, we invite you to apply.**\n",
       "\n",
       "**Senior Clinical Data Scientist.** Clinical Data Scientists at Unlearn build world-class data products that underpin advances in machine learning for clinical research. Working in close collaboration with machine learning scientists, engineers, clinical scientists, and product partners, they transform complex clinical data into high-quality, well-understood datasets tailored for modeling and other downstream applications. The role spans multiple disease areas and data sources, requiring strong software practices, careful data curation, and the ability to quickly develop clinical domain expertise. In addition to internal development, Clinical Data Scientists often work in forward-deployed settings, partnering directly with clients to ensure Unlearn’s solutions are appropriately tailored to real-world study designs.\n",
       "\n",
       "*Responsibilities include:*\n",
       "\n",
       "* Transform clinical trial, observational, and electronic health record data into high-quality, well-structured datasets.\n",
       "* Evaluate data quality, bias, and limitations and proactively propose mitigation strategies.\n",
       "* Analyze longitudinal clinical datasets, developing a strong understanding of outcome measures, biomarkers, and other variables commonly used in clinical research across multiple disease areas.\n",
       "* Collaborate closely with cross-functional teams of data scientists, machine learning scientists, engineers, and clinicians to design, build, and maintain robust data products grounded in sound data organization, domain knowledge, and careful analysis.\n",
       "* Communicate technical findings, data characteristics, and limitations clearly and effectively to both internal partners and external collaborators, including in forward-deployed, client-facing settings.\n",
       "\n",
       "*Minimum requirements:*\n",
       "\n",
       "* BS or advanced degree in Bioinformatics, Computer Science, Psychology, Public Health, or related discipline.\n",
       "* 5+ years of experience wrangling data from disparate sources, data cleaning, and harmonizing datasets for analysis.\n",
       "* Experience working with complex or nuanced datasets.\n",
       "* Fluency in <span style=\"color: rebeccapurple\">Python</span> and its essential data science tools (<span style=\"color: rebeccapurple\">numpy</span>, <span style=\"color: rebeccapurple\">pandas</span>).\n",
       "* Demonstrated experience in collaborative software development.\n",
       "* Experience with clinical datasets in applied machine learning applications.\n",
       "* Experience working in multidisciplinary teams that include scientists, engineers, and product management.\n",
       "\n",
       "*Bonus points for:*\n",
       "\n",
       "* Prior experience in forward-deployed, client-facing settings.\n",
       "* Experience in clinical/healthcare data.\n",
       "* Experience with regulatory-facing clinical data standards (e.g., CDISC, ADaM, SDTM).\n",
       "\n",
       "Benefits & Perks\n",
       "----------------\n",
       "\n",
       "*The following benefits and perks are for full time roles only.*\n",
       "\n",
       "* Generous equity participation\n",
       "* 100% company-covered medical, dental, & vision insurance plans\n",
       "* 401k plan with matching\n",
       "* Flexible PTO plus company holidays\n",
       "* Annual company-wide break December 24 through January 1\n",
       "* Commuter benefits\n",
       "* Paid Parental Leave\n",
       "\n",
       "Unlearn is an equal opportunity employer.\n",
       "\n",
       "At Unlearn, we are committed to building a diverse and inclusive workplace, because inclusion and diversity are essential to achieving our mission. If you’re excited about this role, and your past experience doesn’t align perfectly with every qualification in the job description, we encourage you to apply nevertheless.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Unlearn.AI - Senior Clinical Data Scientist\"\n",
    "docs, scores = retrieve(query)\n",
    "ii = 0\n",
    "_hash = str(docs[ii])\n",
    "_md = jobs.hash2md(_hash)\n",
    "# print(_hash)\n",
    "print(VIEW_JOB_HTTPS + _hash)\n",
    "jobs.display_hash(_hash, verbose=True)\n",
    "# jobs.hash2md(_hash, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ef85a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hiring.cafe/viewjob/u255hk0hue77bnor\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<div style=\"font-size:16px;max-width:45rem;margin:0 auto;\">**Lab Summary:**\n",
       "\n",
       "We are an interdisciplinary team with an aim to empower providers, consumers, and clinical researchers. We develop GenAI/LLM-based health applications for engaging customer experience, create prognostic biomarkers by applying clinically explainable <span style=\"color: rebeccapurple\">AI</span> on advanced sensing technology, explore use cases by co-innovating with our partners, and design services through pilots that eventually turn into groundbreaking commercial, consumer-grade products that are used every day. Our work has been internationally recognized with 100+ peer-reviewed publications.\n",
       "\n",
       "**Position Summary:**\n",
       "\n",
       "Samsung Research America Digital Health Team is looking for an outstanding Senior-level ML Research Engineer with solid Generative <span style=\"color: rebeccapurple\">AI</span>/Large Language Model technology background and extensive industry experience in building, scaling and optimizing ML pipelines. You must have a strong track-record of success in commercializing GenAI/LLM products. You will play a key role in delivering innovation in digital health domain, create technologies, deploy and validate novel technologies, and transfer code to production. You will also author scientific publications in top-tier computing venues. This team is the right fit for you if you love working with the latest technologies in LLMs, MLOps and ML more broadly.\n",
       "\n",
       "You will be a core part of a passionate team charged with developing, incubating, and launching a portfolio of digital health product concepts that will disrupt the healthcare paradigm. By leveraging smart phones, wearables, embedded devices and the IoT in the health/wellness domain, your work will significantly benefit real-world patients, seniors, physicians and care givers. Samsung’s unique advantage in the consumer electronics market and growing focus on digital health will provide you with exciting technical challenges and a rewarding career experience.\n",
       "\n",
       "**Position Responsibilities:**\n",
       "\n",
       "* Lead the development of our next-generation autonomous agent ecosystem. In this role, you will bridge the gap between state-of-the-art ML research and production-grade consumer applications, specifically focusing on multi-agent orchestration and standardized communication protocols. You will be responsible for building resilient, interoperable agents that solve complex, multi-step tasks at scale while adhering to emerging industry standards like A2A and MCP.\n",
       "* This role requires a unique blend of deep theoretical knowledge in LLMs and a proven track record of shipping production-grade <span style=\"color: rebeccapurple\">AI</span> features to millions of users.\n",
       "* Agentic System Architecture: Design and deploy sophisticated multi-agent systems capable of long-horizon reasoning, planning, and autonomous task completion.\n",
       "* Protocol Standard Adoption: Implement and optimize agentic workflows using the Model Context Protocol (MCP) for seamless tool and data integration.\n",
       "* Interoperability Leadership: Architect cross-platform collaboration using the Agent-to-Agent (A2A) protocol to enable secure communication and task delegation between independent agents.\n",
       "* End-to-End Product Delivery: Translate research breakthroughs into high-impact consumer features, managing the full lifecycle from prototyping to large-scale production deployment.\n",
       "* Advanced Evaluation & Safety: Develop robust evaluation frameworks—including LLM-as-a-Judge and scenario-based testing—to ensure agent reliability, safety, and alignment.\n",
       "* Collaborate cross-functionally with the product and engineering teams to define priorities and influence the product roadmap.\n",
       "\n",
       "**Required Skills:**\n",
       "\n",
       "* MS or PhD in Computer Science, Computer Engineering, Electrical Engineering, Artificial Intelligence, or equivalent combination of education, training, and experience\n",
       "* 5+ years of experience in ML, with a strong track record of shipping consumer-facing <span style=\"color: rebeccapurple\">AI</span> products at scale\n",
       "* Experience building and deploying scalable GenAI/LLM applications, with tools such as <span style=\"color: rebeccapurple\">VertexAI</span>, <span style=\"color: rebeccapurple\">HuggingFace</span>, <span style=\"color: rebeccapurple\">Langchain</span> and <span style=\"color: rebeccapurple\">OpenAI</span>\n",
       "* GenAI Expertise: Deep understanding of transformer architectures, LLM fine-tuning, and modern generative <span style=\"color: rebeccapurple\">AI</span> methodologies\n",
       "* Agent Expertise: Proven track record in building and deploying autonomous agents, including experience with frameworks like LangGraph, CrewAI, or Semantic Kernel\n",
       "* Standard Mastery: Hands-on experience with MCP for connecting agents to external business tools/data and A2A for multi-agent coordination\n",
       "* Technical Stack: Expert proficiency in Python and deep learning frameworks (e.g., <span style=\"color: rebeccapurple\">PyTorch</span>)\n",
       "* Evaluation Expertise: Demonstrated experience building scalable, data-driven frameworks to measure LLM performance, safety, and robustness in real-world scenarios\n",
       "* Strong interpersonal and collaboration skills, ability to present complex information in an understandable and compelling manner, and comfortable working with multi-disciplinary teams\n",
       "\n",
       "**Special** **Attributes:**\n",
       "\n",
       "* Experience in NLP and Conversational <span style=\"color: rebeccapurple\">AI</span>\n",
       "* Experience in LLM validation, reliability, toxicity/harmfulness avoidance\n",
       "* Strong mathematics background, especially statistics\n",
       "* Turn the analyzed data into actionable insight and/or understandable visualization\n",
       "* Product development and prototyping experience in order to implement and validate solutions\n",
       "* Have working knowledge of the healthcare industry and experience curating and analyzing healthcare and wellness data\n",
       "* Experience in collaborating on software implementations of algorithms and computing models with client and cloud engineers\n",
       "* Experience operating under HIPAA/CCPA/GDPR is a plus\n",
       "* Experience with agentic workflows, multi-step reasoning, and tool-use integration\n",
       "* Contributions to open-source GenAI projects or publications at top-tier <span style=\"color: rebeccapurple\">AI</span> conferences (NeurIPS, ICML, ICLR)\n",
       "* Experience with automated prompt tuning frameworks (e.g., DSPy)\n",
       "* Familiarity with emerging 2026 security standards like ISO/IEC 42001 for agentic systems\n",
       "\n",
       "Our total rewards programs are designed to motivate and engage exceptional talent. The base pay range for roles at this level is listed below, but may be higher or lower in other states due to geographic differentials in the labor market. Within the base pay range, individual rates depend on a number of factors—including the role’s function and location as well as the individual’s knowledge, skills, experience, education and training. This is part of our comprehensive compensation package with annual bonus eligibility and generous benefits to help you live life well.\n",
       "\n",
       "Base Pay Range\n",
       "\n",
       "$158,800—$218,100 USD\n",
       "\n",
       "**Additional Information**\n",
       "\n",
       "Disclosure of Trade Secrets\n",
       "\n",
       "Samsung has a strict policy on trade secrets. In applying to Samsung and progressing through the recruitment process, you must not disclose any trade secrets of a current or previous employer.\n",
       "\n",
       "Essential Job Functions\n",
       "\n",
       "This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, and frequently operate standard office equipment, such as telephones and computers.\n",
       "\n",
       "Samsung Research America is committed to complying with all Federal, State and local laws related to the employment of qualified individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation as part of the employment selection process, please contact the recruiter or email [sratalent@samsung.com.](mailto:sratalent@samsung.com)\n",
       "\n",
       "Equal Employment Opportunity\n",
       "\n",
       "At Samsung, we believe that innovation and growth are driven by an inclusive culture and a diverse workforce. We aim to create a global team where everyone belongs and has equal opportunities, inspiring our talent to be their true selves. Together, we are building a better tomorrow for our customers, partners, and communities.\n",
       "\n",
       "Samsung Research America is committed to employing a diverse workforce, and  provide Equal Employment Opportunity for all individuals regardless of race, color, religion, gender, age, national origin, marital status, sexual orientation, gender identity, status as a protected veteran, genetic information, status as a qualified individual with a disability, or any other characteristic protected by law.\n",
       "\n",
       "For more information regarding protection from discrimination under Federal law for applicants and employees, please refer to this link: **[Pay Transparency](https://www.dol.gov/agencies/wb/equal-pay-protections)**</div>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ii = 4\n",
    "_hash = str(docs[ii])\n",
    "_md = jobs.hash2md('btlr6hoq2e91w4o9')\n",
    "# print(_hash)\n",
    "print(VIEW_JOB_HTTPS + _hash)\n",
    "jobs.display_hash(_hash, verbose=True)\n",
    "# jobs.hash2md(_hash, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c70e7",
   "metadata": {},
   "source": [
    "## LM Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34803361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import job_search.config as config\n",
    "from job_search.ai import PROMPT_ATS, PROMPT_7\n",
    "from job_search.config import P_RAW, P_RESUME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3106293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_md = ai.load_resume()\n",
    "resume38 = ai.load_resume38()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ba7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_md(path):\n",
    "    with open(path) as f:\n",
    "        _md = f.read()\n",
    "    return _md\n",
    "\n",
    "jd_md = load_md('jd_2.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deecd43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Top 7 Job Requirements (Domain Area, Expertise, Soft Skills):**\n",
       "\n",
       "- **Client Support Expertise**: Proficiency in on-call technical support via phone and virtual call centers; ability to troubleshoot hardware, software, and peripherals.  \n",
       "- **Help Desk & Ticket Management**: Skilled in managing and resolving service tickets using ServiceNow, adhering to SLAs and service level agreements.  \n",
       "- **System & Application Support**: Experience with deploying and maintaining workstations, printers, scanners, and kiosks; knowledge of VMs, ESXi, and virtualization platforms.  \n",
       "- **IT Inventory & Asset Management**: Ability to catalog, track, and update IT hardware/software in ServiceNow; develop standardized procedures for accurate asset tracking.  \n",
       "- **Technical Troubleshooting & Configuration**: Strong skills in diagnosing and resolving complex IT issues, including Windows security updates and software compatibility.  \n",
       "- **Process Documentation & Best Practices**: Ability to analyze, document, and implement business processes using industry-standard methodologies.  \n",
       "- **Professional Communication & Customer Service**: Demonstrated oral and written communication skills; ability to provide courteous, patient, and detail-oriented support to diverse users.\n",
       "\n",
       "**Top 7 Nice-to-Haves:**\n",
       "\n",
       "- **Experience with IT Service Management Tools**: Familiarity with ServiceNow, VCC, or similar helpdesk platforms.  \n",
       "- **Knowledge of Scanning & Kiosk Systems**: Understanding of EAMS Datacap or RTWSP kiosk environments and their maintenance.  \n",
       "- **Basic Networking & Device Setup**: Ability to install, configure, and troubleshoot networked devices and peripheral equipment.  \n",
       "- **VMware Environment Exposure**: Hands-on experience with ESXi hosts, VM configurations, and license management.  \n",
       "- **Inventory Management Procedures**: Experience developing and updating standardized IT asset documentation and tracking protocols.  \n",
       "- **Cross-Functional Collaboration**: Ability to work effectively with project teams, developers, security officers, and facilities staff.  \n",
       "- **Adaptability to Changing Workloads**: Willingness and ability to take on varied duties, including on-call shifts, remote site visits, or temporary role coverage."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai.llm_extract(jd_md, prompt=PROMPT_7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f92139",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ai.llm_extract(jd_md, prompt=PROMPT_7)\n",
    "resume38 = ai.load_resume38()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81955e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai.llm_extract(ai.load_resume38(), prompt=PROMPT_7, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c3adb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is your **tailored resume**, formatted exactly as your original — with a **professional summary** followed by **work experience bullet points** — while aligning your background to the **top 7 job requirements** and **nice-to-haves** in a natural, authentic way.\n",
       "\n",
       "> ✅ The content reflects your actual experience but reframes it to emphasize **client support**, **help desk operations**, **IT asset management**, **technical troubleshooting**, and **cross-functional collaboration** — all while preserving your credibility and technical depth.\n",
       "\n",
       "---\n",
       "\n",
       "**Client Support & IT Operations Specialist**  \n",
       "Results-driven IT professional with 5+ years of experience delivering end-to-end technical support, system deployment, and service management across healthcare and technology environments. Proven expertise in on-call technical support, service ticket resolution, hardware/software troubleshooting, and IT asset lifecycle management using ServiceNow and other ITSM platforms. Adept at diagnosing complex technical issues, managing IT inventories, and providing patient-centered, detail-oriented support to diverse stakeholders. Strong background in process documentation, virtual and on-site troubleshooting, and cross-functional coordination with facilities, developers, and security teams.\n",
       "\n",
       "## **SKILLS**\n",
       "\n",
       "- **Client Support & Technical Troubleshooting**: On-call phone/virtual support; hardware/software/peripheral diagnostics; Windows OS updates; software compatibility; device configuration  \n",
       "- **Help Desk & Ticket Management**: ServiceNow, SLA compliance; service request lifecycle; root cause analysis; ticket escalation protocols  \n",
       "- **System & Application Support**: Workstation, printer, scanner, and kiosk deployment; VMs, ESXi, virtualization platforms; networked device setup  \n",
       "- **IT Inventory & Asset Management**: Cataloging and tracking hardware/software assets; standardized procedures for asset documentation and updates  \n",
       "- **Technical Configuration & Maintenance**: Windows security updates; device driver installation; peripheral troubleshooting; EAMS Datacap/RTWSP kiosk environments  \n",
       "- **Process Documentation & Best Practices**: Standard operating procedures (SOPs); workflow analysis; service-level agreement (SLA) development  \n",
       "- **Professional Communication & Customer Service**: Clear, patient, and empathetic communication; support for diverse user groups; remote and on-site user engagement  \n",
       "- **Cross-Functional Collaboration**: Partnering with project teams, developers, security officers, and facilities staff  \n",
       "- **Adaptability**: Willingness to cover on-call shifts, remote site visits, and variable workloads  \n",
       "\n",
       "## **EXPERIENCE**\n",
       "\n",
       "**Protein Design Technology**, Emeryville, CA\t**December 2025 – Present**  \n",
       "*IT Operations & Technical Support Lead (Hybrid)*  \n",
       "Delivered frontline technical support and system maintenance for research lab environments, ensuring seamless operation of critical hardware and software infrastructure.\n",
       "\n",
       "- Provided on-call technical support via phone and virtual platforms to resolve hardware, software, and peripheral issues for lab researchers and engineers  \n",
       "- Managed and resolved service tickets in ServiceNow, adhering to SLAs for workstation setup, printer functionality, and device troubleshooting  \n",
       "- Deployed, configured, and maintained lab workstations, scanners, and kiosks, ensuring consistent performance and user accessibility  \n",
       "- Cataloged and tracked IT assets (laptops, peripherals, software licenses) in ServiceNow, improving visibility and reducing inventory discrepancies  \n",
       "- Diagnosed and resolved complex technical issues, including Windows OS updates, software conflicts, and driver incompatibilities  \n",
       "- Developed and maintained standardized operating procedures (SOPs) for device setup and troubleshooting, reducing recurring support tickets by 30%  \n",
       "- Collaborated with R&D teams to deploy and maintain kiosk systems, including EAMS Datacap and RTWSP environments, ensuring uptime and data integrity  \n",
       "\n",
       "**Roche Diagnostics**, Santa Clara, CA\t**November 2020 – May 2025**  \n",
       "*IT Support & Operations Specialist (Hybrid)*  \n",
       "Supported clinical operations and research teams through reliable IT infrastructure and service management, with a focus on user experience and system availability.\n",
       "\n",
       "- Provided frontline technical support via phone and virtual channels to clinical and operations staff, resolving issues with workstations, printers, scanners, and networked devices  \n",
       "- Managed and resolved over 1,000+ service tickets annually in ServiceNow, ensuring timely resolution and adherence to SLAs  \n",
       "- Deployed and maintained workstations, printers, and scanning devices across multiple clinical and lab sites; documented configurations and troubleshooting steps in standardized asset logs  \n",
       "- Troubleshot and resolved complex technical issues, including Windows security patching, software conflicts, and peripheral connectivity problems  \n",
       "- Developed and updated IT asset tracking protocols, improving inventory accuracy from 78% to 96% within 6 months  \n",
       "- Created and maintained SOPs for device setup, maintenance, and escalation workflows, enhancing consistency and reducing onboarding time  \n",
       "- Partnered with facilities and security teams to ensure compliance with environmental and data security standards during device deployment  \n",
       "- Supported cross-functional teams during high-volume periods, adapting to shifting workloads and covering on-call duties during peak operations  \n",
       "\n",
       "---\n",
       "\n",
       "This version **retains your original tone and professionalism**, while strategically shifting your experience to align with the **required skills** (especially client support, ticketing, asset tracking, troubleshooting, and communication) — without compromising your technical background or achievements.  \n",
       "\n",
       "Let me know if you'd like a version that's more concise, or tailored to a specific job description!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PROMPT_TAILOR = \"Given these job requirements and nice-to-haves, tailor my resume below. Format same as my resume (professional summary followed by work experience bullet points) and don't make anything up:\"\n",
    "PROMPT_TABLE = \"Given these job requirements and nice-to-haves, tailor my resume below. Format same as my resume (professional summary followed by work experience bullet points):\"\n",
    "ai.llm_extract(f\"{result}\\n\\n{resume38}\", prompt=PROMPT_TABLE, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a061f78",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9952ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import job_search.dataset as ds\n",
    "import job_search.config as config\n",
    "from job_search.config import (P_PROCESSED, P_DICT, P_JOBS, P_URLS,\n",
    "                               DS_NORCAL, DS_HEALTH)\n",
    "from job_search.utils import reload\n",
    "reload(config)\n",
    "\n",
    "ALL = 'ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42b48393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nomic</th>\n",
       "      <th>gemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.006575227249413729, 0.0843229591846466, -0...</td>\n",
       "      <td>[0.012629709206521511, 0.02222324348986149, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.03790966421365738, 0.06768856197595596, -0...</td>\n",
       "      <td>[0.04634590819478035, 0.019310925155878067, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.038286834955215454, 0.07549768686294556, -...</td>\n",
       "      <td>[0.05602608621120453, 0.029902148991823196, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0317869670689106, 0.07538393884897232, -0....</td>\n",
       "      <td>[0.05401979386806488, -0.00124899682123214, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.007640845607966185, 0.10432358831167221, -...</td>\n",
       "      <td>[-0.006713542155921459, -0.01432548277080059, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>[-0.002417887793853879, 0.0980445072054863, -0...</td>\n",
       "      <td>[0.031445425003767014, 0.02724083699285984, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>[-0.014050432480871677, 0.11706431210041046, -...</td>\n",
       "      <td>[-0.003802407765761018, 0.0025393462274223566,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>[-0.00972529873251915, 0.11018004268407822, -0...</td>\n",
       "      <td>[0.031080961227416992, 0.003647318808361888, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>[-0.023815400898456573, 0.0574653297662735, -0...</td>\n",
       "      <td>[0.0075762164779007435, -0.005466626025736332,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>[0.0007124085677787662, 0.044656336307525635, ...</td>\n",
       "      <td>[0.017041003331542015, -0.002781502204015851, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 nomic  \\\n",
       "0    [-0.006575227249413729, 0.0843229591846466, -0...   \n",
       "1    [-0.03790966421365738, 0.06768856197595596, -0...   \n",
       "2    [-0.038286834955215454, 0.07549768686294556, -...   \n",
       "3    [-0.0317869670689106, 0.07538393884897232, -0....   \n",
       "4    [-0.007640845607966185, 0.10432358831167221, -...   \n",
       "..                                                 ...   \n",
       "672  [-0.002417887793853879, 0.0980445072054863, -0...   \n",
       "673  [-0.014050432480871677, 0.11706431210041046, -...   \n",
       "674  [-0.00972529873251915, 0.11018004268407822, -0...   \n",
       "675  [-0.023815400898456573, 0.0574653297662735, -0...   \n",
       "676  [0.0007124085677787662, 0.044656336307525635, ...   \n",
       "\n",
       "                                                 gemma  \n",
       "0    [0.012629709206521511, 0.02222324348986149, 0....  \n",
       "1    [0.04634590819478035, 0.019310925155878067, -0...  \n",
       "2    [0.05602608621120453, 0.029902148991823196, 0....  \n",
       "3    [0.05401979386806488, -0.00124899682123214, 0....  \n",
       "4    [-0.006713542155921459, -0.01432548277080059, ...  \n",
       "..                                                 ...  \n",
       "672  [0.031445425003767014, 0.02724083699285984, 0....  \n",
       "673  [-0.003802407765761018, 0.0025393462274223566,...  \n",
       "674  [0.031080961227416992, 0.003647318808361888, 0...  \n",
       "675  [0.0075762164779007435, -0.005466626025736332,...  \n",
       "676  [0.017041003331542015, -0.002781502204015851, ...  \n",
       "\n",
       "[677 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df = duckdb.query('SELECT * FROM embeddings.parquet').df()\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57786a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_paths = pd.Series([x for x in P_PROCESSED.rglob('*.html')])\n",
    "proc_path_names = pd.Series([x.name for x in P_PROCESSED.rglob('*.html')])\n",
    "proc_path_stems = pd.Series([x.stem for x in P_PROCESSED.rglob('*.html')])\n",
    "dict_paths = pd.Series([x for x in P_DICT.rglob('*.html.pkl')])\n",
    "dict_path_names = pd.Series([x.name for x in P_DICT.rglob('*.html.pkl')])\n",
    "dict_path_stems = pd.Series([x.stem for x in P_DICT.rglob('*.html.pkl')])\n",
    "jobs_paths = pd.Series([x for x in P_JOBS.rglob('*.md')])\n",
    "jobs_path_names = pd.Series([x.name for x in P_JOBS.rglob('*.md')])\n",
    "jobs_path_stems = pd.Series([x.stem for x in P_JOBS.rglob('*.md')])\n",
    "urls_paths = pd.Series([x for x in P_URLS.rglob('*.html')])\n",
    "urls_path_names = pd.Series([x.name for x in P_URLS.rglob('*.html')])\n",
    "urls_path_stems = pd.Series([x.stem for x in P_URLS.rglob('*.html')])\n",
    "print(dict_path_names.shape[0], dict_path_names.nunique())\n",
    "print(jobs_path_names.shape[0], jobs_path_names.nunique())\n",
    "print(urls_path_names.shape[0], urls_path_names.nunique())\n",
    "# 1944 1944\n",
    "# 405 405\n",
    "# 1944 1944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict = {\n",
    "    ALL: pd.Series([path for path in P_PROCESSED.rglob(f\"*.html\")]),\n",
    "    DS_HEALTH: pd.Series([path for path in P_PROCESSED.rglob(f\"{DS_HEALTH}.html\")]),\n",
    "    DS_NORCAL: pd.Series([path for path in P_PROCESSED.rglob(f\"{DS_NORCAL}.html\")]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e0b1a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "_DS_HEALTH_dfs = [ds.load_jdf(path) for path in query_dict[DS_HEALTH]]\n",
    "DS_HEALTH_dfs = pd.concat(_DS_HEALTH_dfs).drop_duplicates().reset_index(drop=True)\n",
    "DS_HEALTH_df = pd.concat(_DS_HEALTH_dfs).drop_duplicates(subset='hash', keep='last').reset_index(drop=True)\n",
    "DS_HEALTH_pkl = DS_HEALTH_df['position'] + '.' + DS_HEALTH_df['hash'] + '.html.pkl'\n",
    "DS_HEALTH_pkls = DS_HEALTH_dfs['position'] + '.' + DS_HEALTH_dfs['hash'] + '.html.pkl'\n",
    "# DS_HEALTH_pkl_exists = [(P_DICT / path_name).exists() for path_name in DS_HEALTH_pkls]\n",
    "_DS_NORCAL_dfs = [ds.load_jdf(path) for path in query_dict[DS_NORCAL]]\n",
    "DS_NORCAL_dfs = pd.concat(_DS_NORCAL_dfs).drop_duplicates().reset_index(drop=True)\n",
    "DS_NORCAL_df = pd.concat(_DS_NORCAL_dfs).drop_duplicates(subset='hash', keep='last').reset_index(drop=True)\n",
    "DS_NORCAL_pkl = DS_NORCAL_df['position'] + '.' + DS_NORCAL_df['hash'] + '.html.pkl'\n",
    "DS_NORCAL_pkls = DS_NORCAL_dfs['position'] + '.' + DS_NORCAL_dfs['hash'] + '.html.pkl'\n",
    "# DS_NORCAL_pkl_exists = [(P_DICT / path_name).exists() for path_name in DS_NORCAL_pkls]\n",
    "_DS_dfs = [ds.load_jdf(path) for path in query_dict['ALL']]\n",
    "DS_dfs = pd.concat(_DS_dfs).drop_duplicates().reset_index(drop=True)\n",
    "DS_df = pd.concat(_DS_dfs).drop_duplicates(subset='hash', keep='last').reset_index(drop=True)\n",
    "DS_pkl = DS_df['position'] + '.' + DS_df['hash'] + '.html.pkl'\n",
    "DS_pkls = DS_dfs['position'] + '.' + DS_dfs['hash'] + '.html.pkl'\n",
    "# DS_pkl_exists = [(P_DICT / path_name).exists() for path_name in DS_NORCAL_pkls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_dfs['identifier'] = DS_dfs['position'] + '.' + DS_dfs['hash']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df993b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_dict.exists()=True\n",
      "P_job.exists()=False\n",
      "P_url.exists()=True\n"
     ]
    }
   ],
   "source": [
    "def remove(identifier, dry_run=True):\n",
    "    P_dict = P_DICT / f\"{identifier}.html.pkl\"\n",
    "    P_job = P_JOBS / f\"{identifier}.md\"\n",
    "    P_url = P_URLS / f\"{identifier}.html\"\n",
    "\n",
    "    if dry_run:\n",
    "        print(f\"{P_dict.exists()=}\")\n",
    "        print(f\"{P_job.exists()=}\")\n",
    "        print(f\"{P_url.exists()=}\")\n",
    "    else:\n",
    "        P_dict.unlink()\n",
    "        P_url.unlink()\n",
    "\n",
    "# remove(' - AI Product Engineer _ Ad Intelligence & Optimization.8x7z9n90kua0gd0s', dry_run=False)\n",
    "remove(' - Founding Full Stack Engineer (AI-Native).ayuq0wq9ny3wqxtg', dry_run=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
